{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.16.1\r\n",
      "Uninstalling tensorflow-2.16.1:\r\n",
      "  Would remove:\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/bin/import_pb_to_tensorboard\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/bin/saved_model_cli\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/bin/tensorboard\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/bin/tf_upgrade_v2\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/bin/tflite_convert\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/bin/toco\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/bin/toco_from_protos\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages/tensorflow-2.16.1.dist-info/*\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages/tensorflow/*\r\n",
      "Proceed (Y/n)? ^C\r\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\r\n",
      "\u001B[0mCollecting tensorflow-macos\r\n",
      "  Downloading tensorflow_macos-2.16.2-cp311-cp311-macosx_12_0_arm64.whl (2.1 kB)\r\n",
      "Collecting tensorflow==2.16.2\r\n",
      "  Downloading tensorflow-2.16.2-cp311-cp311-macosx_12_0_arm64.whl (227.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m227.0/227.0 MB\u001B[0m \u001B[31m3.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:02\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: absl-py>=1.0.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.12.1)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.3.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (24.1)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (4.25.5)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (65.5.1)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.66.2)\r\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (2.16.2)\r\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (3.6.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (0.37.1)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorflow==2.16.2->tensorflow-macos) (1.23.5)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.16.2->tensorflow-macos) (0.38.4)\r\n",
      "Requirement already satisfied: rich in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (13.9.2)\r\n",
      "Requirement already satisfied: namex in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.13.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow==2.16.2->tensorflow-macos) (2024.8.30)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (3.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2->tensorflow-macos) (2.1.5)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (2.18.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2->tensorflow-macos) (0.1.2)\r\n",
      "Installing collected packages: tensorflow, tensorflow-macos\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.16.1\r\n",
      "    Uninstalling tensorflow-2.16.1:\r\n",
      "      Successfully uninstalled tensorflow-2.16.1\r\n",
      "Successfully installed tensorflow-2.16.2 tensorflow-macos-2.16.2\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow\n",
    "!pip install tensorflow-macos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.4.1\r\n",
      "Uninstalling torch-2.4.1:\r\n",
      "  Would remove:\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/bin/convert-caffe2-to-onnx\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/bin/convert-onnx-to-caffe2\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/bin/torchrun\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages/functorch/*\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages/torch-2.4.1.dist-info/*\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages/torch/*\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages/torchgen/*\r\n",
      "Proceed (Y/n)?   Successfully uninstalled torch-2.4.1\r\n",
      "Found existing installation: torchvision 0.19.1\r\n",
      "Uninstalling torchvision-0.19.1:\r\n",
      "  Would remove:\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages/torchvision-0.19.1.dist-info/*\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages/torchvision/*\r\n",
      "Proceed (Y/n)?   Successfully uninstalled torchvision-0.19.1\r\n",
      "Found existing installation: torchaudio 2.4.1\r\n",
      "Uninstalling torchaudio-2.4.1:\r\n",
      "  Would remove:\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages/torchaudio-2.4.1.dist-info/*\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages/torchaudio/*\r\n",
      "    /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages/torio/*\r\n",
      "Proceed (Y/n)?   Successfully uninstalled torchaudio-2.4.1\r\n",
      "yes: stdout: Broken pipe\r\n",
      "Looking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\r\n",
      "Collecting torch\r\n",
      "  Using cached torch-2.4.1-cp311-none-macosx_11_0_arm64.whl (62.1 MB)\r\n",
      "Collecting torchvision\r\n",
      "  Using cached torchvision-0.19.1-cp311-cp311-macosx_11_0_arm64.whl (1.7 MB)\r\n",
      "Collecting torchaudio\r\n",
      "  Using cached torchaudio-2.4.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\r\n",
      "Requirement already satisfied: filelock in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from torch) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from torch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from torch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from torch) (2024.9.0)\r\n",
      "Requirement already satisfied: numpy in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from torchvision) (1.23.5)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from torchvision) (10.4.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mukhit.ismailov/Work/MLModel/venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\r\n",
      "Installing collected packages: torch, torchvision, torchaudio\r\n",
      "Successfully installed torch-2.4.1 torchaudio-2.4.1 torchvision-0.19.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!yes | pip uninstall torch torchvision torchaudio\n",
    "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cpu/torch_stable.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\r\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/1.2 MB\u001B[0m \u001B[31m17.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: sentencepiece\r\n",
      "Successfully installed sentencepiece-0.2.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "--------------------\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Our policies apply to all employees, without distinction of position or title, including those under probation, tenured employees and interns. This ensures consistency and transparency and helps to create an enabling culture aligned with organizational beliefs and purpose. You may also share your concerns at myvoice@g42.ai.\n",
      "\n",
      "\n",
      "Summary: The Salary breakdown we follow is: Basic Salary – 60% , Housing Allowance – 30% , Transportation Allowance - 10%. These three elements form the basis for Bonus calculations. You can access your pay slip through OMNI. Salary is paid monthly before the last day of the month.\n",
      "\n",
      "\n",
      "Summary: You will be entitled to an annual airfare allowance as mentioned in your offer letter at the time of joining. The allowance will be credited in 12 equal installments, along with your monthly salary. UAE Nationals are entitled to one month’s salary as annual air fare allowance.\n",
      "\n",
      "\n",
      "Summary: Workmen Compensation Insurance – This is a mandatory insurance coverage to all employees. Medical Insurance (for family) – All employees are covered under the Company group health insurance plan. Life Insurance - We offer life insurance to protect your loved ones in case of an unfortunate disability or death.\n",
      "\n",
      "\n",
      "Summary: Employees on Golden Visa must submit a copy of their visa and Emirates ID along with the other requirements in the table above. Employees are encouraged to use the MyDaman app for quick access to details of insurance benefits and digital insurance cards.\n",
      "\n",
      "\n",
      "Summary: Salary reviews are organized yearly and cover all aspects of reward as well as bonus, at the Group's discretion and based on your performance. Probation period All employees are subject to a probation of six months.\n",
      "\n",
      "\n",
      "Summary: Work from outside of G42 offices, within UAE, 50% of the time each week. During Ramadan, we reduce our working hours by two hours as per the country’s Labour Law.\n",
      "\n",
      "\n",
      "Summary: G42 offers 25 working days fully paid leave as annual leave per year. Overtime will only be recognized and paid when it is specifically and exceptionally requested by the Line Manager.\n",
      "\n",
      "\n",
      "Summary: You are entitled to a sick leave of upto 90 calendar days per year, after the completion of your probation period. Any sick leave during probation will be considered as unpaid leave, as provided in the UAE Labour Law. Hajj leave can be extended up to 22 unpaid working days.\n",
      "\n",
      "\n",
      "Summary: Employees called upon for national service should apply and have the leave approved on OMNI. Time spent in military service will be counted towards length of service and taken into account for pension and/or end of service gratuity pay out.\n",
      "\n",
      "\n",
      "Summary: Employees in the UAE are entitled to the following public holidays:Gregorian New Year: 1 January (1 day) Eid Al Fitr: From last day of the Islamic month of Ramadan to 3 Shawwal* (4 days)\n",
      "\n",
      "\n",
      "Summary: An employee can choose to end their services by submitting a formal resignation letter. The contractual notice period must be respected while considering the last day of work. Employees can claim reimbursement for the membership fee for one (the lowest fee) such accredited organization/institution, relevant to their role.\n",
      "\n",
      "\n",
      "Summary: The retirement age for expatriate residents is 60. An employee who has skills which are considered rare can continue to work after this age limit. You are entitled to an end of service gratuity payment as per local UAE labor law.\n",
      "\n",
      "\n",
      "Summary: You can also track the status of your visa and Emirates ID applications. You might be in need of official letters from your employer and sponsor for legal documentation in UAE. You may request these *letters through OMNI and the letter will be issued in 48 hours.\n",
      "\n",
      "\n",
      "Summary: Our policies apply to all employees, without distinction of position or title, including those under probation, tenured employees and interns. This ensures consistency and transparency and helps to create an enabling culture aligned with organizational beliefs and purpose. You may also share your concerns at myvoice@g42.ai. \n",
      "\n",
      "The Salary breakdown we follow is: Basic Salary – 60% , Housing Allowance – 30% , Transportation Allowance - 10%. These three elements form the basis for Bonus calculations. You can access your pay slip through OMNI. Salary is paid monthly before the last day of the month. \n",
      "\n",
      "You will be entitled to an annual airfare allowance as mentioned in your offer letter at the time of joining. The allowance will be credited in 12 equal installments, along with your monthly salary. UAE Nationals are entitled to one month’s salary as annual air fare allowance. \n",
      "\n",
      "Workmen Compensation Insurance – This is a mandatory insurance coverage to all employees. Medical Insurance (for family) – All employees are covered under the Company group health insurance plan. Life Insurance - We offer life insurance to protect your loved ones in case of an unfortunate disability or death. \n",
      "\n",
      "Employees on Golden Visa must submit a copy of their visa and Emirates ID along with the other requirements in the table above. Employees are encouraged to use the MyDaman app for quick access to details of insurance benefits and digital insurance cards. \n",
      "\n",
      "Salary reviews are organized yearly and cover all aspects of reward as well as bonus, at the Group's discretion and based on your performance. Probation period All employees are subject to a probation of six months. \n",
      "\n",
      "Work from outside of G42 offices, within UAE, 50% of the time each week. During Ramadan, we reduce our working hours by two hours as per the country’s Labour Law. \n",
      "\n",
      "G42 offers 25 working days fully paid leave as annual leave per year. Overtime will only be recognized and paid when it is specifically and exceptionally requested by the Line Manager. \n",
      "\n",
      "You are entitled to a sick leave of upto 90 calendar days per year, after the completion of your probation period. Any sick leave during probation will be considered as unpaid leave, as provided in the UAE Labour Law. Hajj leave can be extended up to 22 unpaid working days. \n",
      "\n",
      "Employees called upon for national service should apply and have the leave approved on OMNI. Time spent in military service will be counted towards length of service and taken into account for pension and/or end of service gratuity pay out. \n",
      "\n",
      "Employees in the UAE are entitled to the following public holidays:Gregorian New Year: 1 January (1 day) Eid Al Fitr: From last day of the Islamic month of Ramadan to 3 Shawwal* (4 days) \n",
      "\n",
      "An employee can choose to end their services by submitting a formal resignation letter. The contractual notice period must be respected while considering the last day of work. Employees can claim reimbursement for the membership fee for one (the lowest fee) such accredited organization/institution, relevant to their role. \n",
      "\n",
      "The retirement age for expatriate residents is 60. An employee who has skills which are considered rare can continue to work after this age limit. You are entitled to an end of service gratuity payment as per local UAE labor law. \n",
      "\n",
      "You can also track the status of your visa and Emirates ID applications. You might be in need of official letters from your employer and sponsor for legal documentation in UAE. You may request these *letters through OMNI and the letter will be issued in 48 hours.\n",
      "CPU times: user 2min 46s, sys: 1min 7s, total: 3min 54s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import PyPDF2\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "batch_size = 2048\n",
    "# Function to summarize the extracted text\n",
    "# def summarize_text(text):\n",
    "#     summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
    "#     summary = summarizer(text, max_length=1000, min_length=30, do_sample=False, truncation=True)\n",
    "#     return summary[0]['summary_text']\n",
    "\n",
    "def summarize_long_text(text):\n",
    "    chunks = [text[i:i + batch_size] for i in range(0, len(text), batch_size)]\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
    "    summaries = [summarizer(chunk, max_length=130, min_length=30, do_sample=False, truncation=True)[0]['summary_text'] for chunk in chunks]\n",
    "    for i, summary in enumerate(summaries):\n",
    "        print(f\"Summary: {summary}\\n\\n\")\n",
    "    return ' \\n\\n'.join(summaries)\n",
    "\n",
    "# Main execution\n",
    "pdf_path = \"/Users/mukhit.ismailov/Work/MLModel/files/hr_policy.pdf\"  # Specify your PDF file path\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "# print(extracted_text)\n",
    "\n",
    "# Summarize the extracted text\n",
    "if extracted_text:\n",
    "    print(\"--------------------\")\n",
    "    print(\"--------------------\")\n",
    "    print(\"--------------------\")\n",
    "    summary_concat = summarize_long_text(extracted_text)\n",
    "    print(f\"Summary: {summary_concat}\")\n",
    "    # summary = summarize_text(summary_concat)\n",
    "    # print(f\"Summary: {summary}\")\n",
    "else:\n",
    "    print(\"No text found in the PDF.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nPegasusTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Load the model and tokenizer\u001B[39;00m\n\u001B[1;32m      4\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgoogle/pegasus-large\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 5\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mPegasusTokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m(model_name)\n\u001B[1;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m PegasusForConditionalGeneration\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpegasus_summarize\u001B[39m(text):\n",
      "File \u001B[0;32m~/Work/MLModel/venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:1637\u001B[0m, in \u001B[0;36mDummyObject.__getattribute__\u001B[0;34m(cls, key)\u001B[0m\n\u001B[1;32m   1635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_from_config\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1636\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(key)\n\u001B[0;32m-> 1637\u001B[0m \u001B[43mrequires_backends\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backends\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Work/MLModel/venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:1625\u001B[0m, in \u001B[0;36mrequires_backends\u001B[0;34m(obj, backends)\u001B[0m\n\u001B[1;32m   1623\u001B[0m failed \u001B[38;5;241m=\u001B[39m [msg\u001B[38;5;241m.\u001B[39mformat(name) \u001B[38;5;28;01mfor\u001B[39;00m available, msg \u001B[38;5;129;01min\u001B[39;00m checks \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m available()]\n\u001B[1;32m   1624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m failed:\n\u001B[0;32m-> 1625\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(failed))\n",
      "\u001B[0;31mImportError\u001B[0m: \nPegasusTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"google/pegasus-large\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "def pegasus_summarize(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=30, length_penalty=2.0)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "# Example usage\n",
    "pdf_path = \"/Users/mukhit.ismailov/Work/MLModel/files/hr_policy.pdf\"  # Specify your PDF file path\n",
    "long_text = extract_text_from_pdf(pdf_path)\n",
    "summary = pegasus_summarize(long_text)\n",
    "print(summary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pytesseract import Output\n",
    "import pandas as pd\n",
    "import pypdfium2 as pdfium\n",
    "\n",
    "\n",
    "def main():\n",
    "    s3_bucket = 'vantage-data-sample-tmp'\n",
    "    src_folder = 'OCR/input/'\n",
    "\n",
    "    ocr_extract = OcrExtract(s3_bucket, src_folder)\n",
    "    df = ocr_extract.process_images()\n",
    "    df = ocr_extract.summarize_text(df)\n",
    "    api.save(df)\n",
    "\n",
    "\n",
    "class OcrExtract:\n",
    "\n",
    "    def __init__(self, s3_bucket, src_folder):\n",
    "        self.src_folder = src_folder\n",
    "        self.s3_bucket = s3_bucket\n",
    "\n",
    "    def convert_pdf2image(self):\n",
    "        filenames = []\n",
    "        item_list = api.get_files_from_s3(self.s3_bucket, self.src_folder)\n",
    "        for item in item_list:\n",
    "            if str(item.key).endswith('pdf'):\n",
    "                filename = api.load_file_from_s3(item)\n",
    "                pdf = pdfium.PdfDocument(filename)\n",
    "                for i in range(len(pdf)):\n",
    "                    page = pdf[i]\n",
    "                    image = page.render(scale=4).to_pil()\n",
    "                    file_name = filename.split(\"/\")[-1]\n",
    "                    file_name = f\"{file_name}_page{i+1:03d}.jpg\"\n",
    "                    image.save(file_name)\n",
    "                    filenames.append(file_name)\n",
    "        return filenames\n",
    "\n",
    "    def get_filenames(self) -> list:\n",
    "        try:\n",
    "            item_list = api.get_files_from_s3(self.s3_bucket, self.src_folder)\n",
    "            filenames = []\n",
    "            for item in item_list:\n",
    "                filename = api.load_file_from_s3(item)\n",
    "                if not filename.endswith('/') and not filename.endswith('__') and not filename.endswith('pdf'):\n",
    "                    filenames.append(filename)\n",
    "            if not filenames:\n",
    "                LOG.exception(f\"Caught an exception during get_filenames() - no files found in {self.src_folder}\")\n",
    "            return filenames\n",
    "        except Exception as e:\n",
    "            LOG.exception(f\"Caught an exception during get_filenames() - {e}\")\n",
    "\n",
    "    def get_image_data(self, filename) -> pd.DataFrame:\n",
    "        try:\n",
    "            return pytesseract.image_to_data(Image.open(filename),lang = 'eng+ara', output_type=Output.DATAFRAME)\n",
    "        except Exception as e:\n",
    "            LOG.exception(f\"Caught an exception during get_image_data() - {e}\")\n",
    "\n",
    "    def create_image_segment_tesseract(self, image_data, index, text_index, texts) -> dict:\n",
    "        try:\n",
    "            xpos = image_data['left'][index]\n",
    "            ypos = image_data['top'][index]\n",
    "            width = image_data['width'][index]\n",
    "            height = image_data['height'][index]\n",
    "            shape = \"RECTANGLE\"\n",
    "            text = texts[text_index]\n",
    "            coordinates = [xpos, ypos, xpos + width, ypos, xpos + width, ypos + height, xpos, ypos + height]\n",
    "\n",
    "            return {\n",
    "                \"coordinates\": coordinates,\n",
    "                \"shape\": shape,\n",
    "                \"object_label\": None,\n",
    "                \"text\": text\n",
    "            }\n",
    "        except Exception as e:\n",
    "            LOG.exception(f\"Caught an exception during create_image_segment_tesseract() - {e}\")\n",
    "\n",
    "    def populate_text(self, image_data, getting_sentences_id) -> list:\n",
    "        try:\n",
    "            text_result = []\n",
    "            for index in getting_sentences_id[0]:\n",
    "                text_result.append(str(image_data['text'][index]))\n",
    "            return text_result\n",
    "        except Exception as e:\n",
    "            LOG.exception(f\"Caught an exception during populate_text() - {e}\")\n",
    "\n",
    "\n",
    "    def process_ocr_boxes(self, image_data) -> list:\n",
    "        try:\n",
    "            convert_d = np.asarray(image_data['level'])\n",
    "            getting_sentences_id = np.where(convert_d == 5)\n",
    "            texts = self.populate_text(image_data, getting_sentences_id)\n",
    "            image_segments = []\n",
    "            for text_index, index in enumerate(getting_sentences_id[0]):\n",
    "                if len(texts[text_index].strip()) > 0:\n",
    "                    image_segments.append(self.create_image_segment_tesseract(image_data, index, text_index, texts))\n",
    "            return image_segments, texts\n",
    "        except Exception as e:\n",
    "            LOG.exception(f\"Caught an exception during process_ocr_boxes() - {e}\")\n",
    "\n",
    "\n",
    "    def process_images(self, return_with_boxes=False) -> pd.DataFrame:\n",
    "        try:\n",
    "            filenames_pdf = self.convert_pdf2image()\n",
    "            filenames_image = self.get_filenames()\n",
    "            filenames = filenames_pdf + filenames_image\n",
    "            data = []  # Initialize an empty list\n",
    "            for filename in filenames:\n",
    "                file_name = filename.split(\"/\")[-1]\n",
    "                image_data = self.get_image_data(filename)\n",
    "                output, text_output = self.process_ocr_boxes(image_data)\n",
    "                print(f\"----{file_name}----\")\n",
    "                print(\" \".join(text_output))\n",
    "                # Determine if the file is a PDF or an image based on the extension\n",
    "                pdf_or_image = 'pdf' if \".pdf\" in filename else 'image'\n",
    "                # Create a dictionary and append it to the list\n",
    "                data.append({\n",
    "                    'filename': file_name,\n",
    "                    'pdf_or_image': pdf_or_image,\n",
    "                    'text_output': \" \".join(text_output)\n",
    "                })\n",
    "            # Convert the list of dictionaries into a DataFrame\n",
    "            df_combined = pd.DataFrame(data)\n",
    "            return df_combined\n",
    "        except Exception as e:\n",
    "            LOG.exception(f\"Caught an exception during process_images() - {e}\")\n",
    "\n",
    "    def summarize_text(self, df):\n",
    "        df['text_summarized'] = df['text_output'].apply(self.summarize_long_text)\n",
    "        return df\n",
    "\n",
    "    def summarize_long_text(self, text):\n",
    "        import torch\n",
    "        from transformers import pipeline\n",
    "        batch_size = 2048\n",
    "        device = 0 if torch.cuda.is_available() else -1\n",
    "        chunks = [text[i:i + batch_size] for i in range(0, len(text), batch_size)]\n",
    "        summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
    "        summaries = [summarizer(chunk, max_length=130, min_length=30, do_sample=False, truncation=True)[0]['summary_text'] for chunk in chunks]\n",
    "        for i, summary in enumerate(summaries):\n",
    "            print(f\"Summary: {summary}\\n\\n\")\n",
    "        return ' \\n\\n'.join(summaries)\n",
    "\n",
    "\n",
    "main()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import pytesseract\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# from pytesseract import Output\n",
    "# import pandas as pd\n",
    "# import pypdfium2 as pdfium\n",
    "#\n",
    "#\n",
    "# def main():\n",
    "#     s3_bucket = 'vantage-data-sample-tmp'\n",
    "#     src_folder = 'OCR/input/'\n",
    "#     tgt_folder = 'OCR/output/'\n",
    "#\n",
    "#     ocr_extract = OcrExtract(s3_bucket, src_folder, tgt_folder)\n",
    "#     ocr_extract.process_images(s3_bucket, src_folder, tgt_folder)\n",
    "#\n",
    "#\n",
    "# class OcrExtract:\n",
    "#     '''\n",
    "#     Processes images and extracts english and arabic texts into a dataframe.\n",
    "#     '''\n",
    "#     def __init__(self, s3_bucket, src_folder, tgt_folder):\n",
    "#         self.src_folder = src_folder\n",
    "#         self.tgt_folder = tgt_folder\n",
    "#         self.s3_bucket = s3_bucket\n",
    "#\n",
    "#     # def convert_pdf2image(self):\n",
    "#\n",
    "#     def convert_pdf2image(self,s3_bucket,src_folder):\n",
    "#         '''\n",
    "#         Finds PDF files in s3 path, converts them to JPG images and uploads back to s3 path.\n",
    "#\n",
    "#         :param s3_bucket (str): s3 bucket name\n",
    "#         :param src_folder (str): s3 path\n",
    "#         :return: None\n",
    "#         '''\n",
    "#         try:\n",
    "#             item_list = api.get_files_from_s3(s3_bucket, src_folder)\n",
    "#             for item in item_list:\n",
    "#                 if str(item.key).endswith('pdf'):\n",
    "#                     filename = api.load_file_from_s3(item)\n",
    "#                     pdf = pdfium.PdfDocument(filename)\n",
    "#                     for i in range(len(pdf)):\n",
    "#                         page = pdf[i]\n",
    "#                         image = page.render(scale=4).to_pil()\n",
    "#                         file_name = filename.split(\"/\")[-1]\n",
    "#                         image.save(f\"{file_name}_{i:03d}.jpg\")\n",
    "#                         api.load_file_to_s3(f\"{file_name}_{i:03d}.jpg\", s3_bucket, f\"{src_folder}{file_name}_{i:03d}.jpg\")\n",
    "#         except Exception as e:\n",
    "#             LOG.exception(f\"Caught an exception during convert_pdf2image() - {e}\")\n",
    "#\n",
    "#     def get_filenames(self, s3_bucket, src_folder) -> list:\n",
    "#         '''\n",
    "#         Method to load files available on s3 path.\n",
    "#\n",
    "#         :param s3_bucket (str): s3 bucket name\n",
    "#         :param src_folder (str): s3 path\n",
    "#         :return: list of file names\n",
    "#         '''\n",
    "#         try:\n",
    "#             item_list = api.get_files_from_s3(s3_bucket, src_folder)\n",
    "#             filenames = []\n",
    "#             for item in item_list:\n",
    "#                 filename = api.load_file_from_s3(item)\n",
    "#                 if not filename.endswith('/') and not filename.endswith('__') and not filename.endswith('pdf'):\n",
    "#                     filenames.append(filename)\n",
    "#             if not filenames:\n",
    "#                 LOG.exception(f\"Caught an exception during get_filenames() - no files found in {src_folder}\")\n",
    "#             return filenames\n",
    "#         except Exception as e:\n",
    "#             LOG.exception(f\"Caught an exception during get_filenames() - {e}\")\n",
    "#\n",
    "#     def get_image_data(self, filename) -> pd.DataFrame:\n",
    "#         '''\n",
    "#         Method to extract english and arabic text with coordinates and shape details from images into pandas dataframe.\n",
    "#\n",
    "#         :param filename (str): file name\n",
    "#         :return: dataframe\n",
    "#         '''\n",
    "#         try:\n",
    "#             return pytesseract.image_to_data(Image.open(filename),lang = 'eng+ara', output_type=Output.DATAFRAME)\n",
    "#         except Exception as e:\n",
    "#             LOG.exception(f\"Caught an exception during get_image_data() - {e}\")\n",
    "#\n",
    "#     def create_image_segment_tesseract(self, image_data, index, text_index, texts) -> dict:\n",
    "#         '''\n",
    "#         Method to extract coordinates and shape information from output dataframe.\n",
    "#\n",
    "#         :param image_data (df): dataframe with extracted information from the image\n",
    "#         :param index (int): index value of the row that contains text value\n",
    "#         :param text_index (int): index value of the row of the getting_sentences_id[0]\n",
    "#         :param texts (list): list of all text values from the image\n",
    "#         :return: dictionary with coordinates and shape details from the image\n",
    "#         '''\n",
    "#         try:\n",
    "#             xpos = image_data['left'][index]\n",
    "#             ypos = image_data['top'][index]\n",
    "#             width = image_data['width'][index]\n",
    "#             height = image_data['height'][index]\n",
    "#             shape = \"RECTANGLE\"\n",
    "#             text = texts[text_index]\n",
    "#             coordinates = [xpos, ypos, xpos + width, ypos, xpos + width, ypos + height, xpos, ypos + height]\n",
    "#\n",
    "#             return {\n",
    "#                 \"coordinates\": coordinates,\n",
    "#                 \"shape\": shape,\n",
    "#                 \"object_label\": None,\n",
    "#                 \"text\": text\n",
    "#             }\n",
    "#         except Exception as e:\n",
    "#             LOG.exception(f\"Caught an exception during create_image_segment_tesseract() - {e}\")\n",
    "#\n",
    "#     def populate_text(self, image_data, getting_sentences_id) -> list:\n",
    "#         '''\n",
    "#         Method to extract content from the rows that were identified as having text.\n",
    "#\n",
    "#         :param image_data (df): dataframe with extracted information from the image\n",
    "#         :param getting_sentences_id (array): numpy array with index values of rows containing text content\n",
    "#         :return: list with text values from the image\n",
    "#         '''\n",
    "#         try:\n",
    "#             text_result = []\n",
    "#             for index in getting_sentences_id[0]:\n",
    "#                 text_result.append(str(image_data['text'][index]))\n",
    "#             return text_result\n",
    "#         except Exception as e:\n",
    "#             LOG.exception(f\"Caught an exception during populate_text() - {e}\")\n",
    "#\n",
    "#\n",
    "#     def process_ocr_boxes(self, image_data) -> list:\n",
    "#         '''\n",
    "#         Method to process images, extract rows with text, cooridnates and shape details into a list.\n",
    "#\n",
    "#         :param image_data (df): dataframe with extracted information from the image\n",
    "#         :return: list with image segments and list with text values from the image\n",
    "#         '''\n",
    "#         try:\n",
    "#             convert_d = np.asarray(image_data['level'])\n",
    "#             getting_sentences_id = np.where(convert_d == 5)\n",
    "#             texts = self.populate_text(image_data, getting_sentences_id)\n",
    "#             image_segments = []\n",
    "#             for text_index, index in enumerate(getting_sentences_id[0]):\n",
    "#                 if len(texts[text_index].strip()) > 0:\n",
    "#                     image_segments.append(self.create_image_segment_tesseract(image_data, index, text_index, texts))\n",
    "#             return image_segments, texts\n",
    "#         except Exception as e:\n",
    "#             LOG.exception(f\"Caught an exception during process_ocr_boxes() - {e}\")\n",
    "#\n",
    "#\n",
    "#     def save_output(self, s3_bucket, tgt_folder, df, file_name):\n",
    "#         '''\n",
    "#         Optional method to save output df as a csv on s3 location. Can be used in case each image output needs to be saved separately.\n",
    "#\n",
    "#         :param s3_bucket (str): s3 bucket name\n",
    "#         :param tgt_folder (str): target s3 path\n",
    "#         :param df (df): dataframe to be saved\n",
    "#         :param file_name (str): output file name\n",
    "#         :return: None\n",
    "#         '''\n",
    "#         try:\n",
    "#             df.to_csv(f\"{file_name}.csv\", encoding='utf-8', index=False)\n",
    "#             api.load_file_to_s3(f\"{file_name}.csv\", s3_bucket, f\"{tgt_folder}{file_name}.csv\")\n",
    "#         except Exception as e:\n",
    "#             LOG.exception(f\"Caught an exception during save_output() - {e}\")\n",
    "#\n",
    "#     def save_output_df(self, df):\n",
    "#         '''\n",
    "#         Method to save output df as a parquet file on s3 location. The df will contain output combined from all images and saved as one parquet file.\n",
    "#\n",
    "#         :param df (df): dataframe to be saved\n",
    "#         :return: None\n",
    "#         '''\n",
    "#         try:\n",
    "#             api.save(df)\n",
    "#         except Exception as e:\n",
    "#             LOG.exception(f\"Caught an exception during save_output_df() - {e}\")\n",
    "#\n",
    "#\n",
    "#     def process_images(self, s3_bucket, src_folder, tgt_folder):\n",
    "#         '''\n",
    "#         Main method to process images.\n",
    "#\n",
    "#         :param s3_bucket (str): s3 bucket name\n",
    "#         :param src_folder (str): input s3 path\n",
    "#         :param tgt_folder (str): target s3 path\n",
    "#         :return None\n",
    "#         '''\n",
    "#         try:\n",
    "#             self.convert_pdf2image(s3_bucket,src_folder)\n",
    "#             filenames = self.get_filenames(s3_bucket, src_folder)\n",
    "#             df_combined = pd.DataFrame()\n",
    "#             for filename in filenames:\n",
    "#                 file_name = filename.split(\"/\")[-1]\n",
    "#                 image_data = self.get_image_data(filename)\n",
    "#                 output, text_output = self.process_ocr_boxes(image_data)\n",
    "#                 print(f\"----{file_name}----\")\n",
    "#                 print(\" \".join(text_output))\n",
    "#                 df = pd.DataFrame(output)\n",
    "#                 df['filename'] = file_name\n",
    "#                 for col in df.columns:\n",
    "#                     df[col] = df[col].apply(lambda s: str(s)).astype('str')\n",
    "#                 # self.save_output(s3_bucket, tgt_folder, df, file_name)\n",
    "#                 df_combined = pd.concat([df_combined, df])\n",
    "#             self.save_output_df(df_combined)\n",
    "#         except Exception as e:\n",
    "#             LOG.exception(f\"Caught an exception during process_images() - {e}\")\n",
    "#\n",
    "# # define s3 bucket, and input and output paths\n",
    "# main()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men.'}]\n",
      "CPU times: user 19.7 s, sys: 4.86 s, total: 24.6 s\n",
      "Wall time: 8.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "# device = -1\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=device)\n",
    "\n",
    "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))\n",
    "# >>> [{'summary_text': 'Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men.'}]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
